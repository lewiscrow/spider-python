## Python网络爬虫学习-day1
本次课程呢主要就是网络爬虫的教学，打算分一个礼拜讲完。其中涉及到的内容有**爬虫的基本了解、爬虫相关库的使用、URL Error异常处理、cookie的使用、正则表达式处理资源、基于scrapy框架爬取内容实战、模拟浏览器爬取内容实战**（说不定根本不会坚持到那时候哈哈哈）。今天是第一天，就开个头，讲一下爬虫的基本了解以及爬取的原理。
#### 1、什么是爬虫
>网络爬虫（又称为网页蜘蛛，网络机器人，在FOAF社区中间，更经常的称为网页追逐者），是一种按照一定的规则，自动地抓取万维网信息的程序或者脚本。另外一些不常使用的名字还有蚂蚁、自动索引、模拟程序或者蠕虫。

现在小到公司、大到政府机关网站，无时无刻都有爬虫在爬取数据。比如说12306，这个世界上最大的铁路售票系统，身上爬满了无数个网络爬虫，我们用到的抢票软件，其实就是这些爬虫的衍生品。所以抢不到票时也不用怪12306，爬虫在不断进步，就算是用网红的脸人家也阻止不了爬虫。再比如说搜索引擎，其实百度就是不断的通过深度爬取把尽可能多的网站放到自己服务器上，再根据一种全文搜索引擎去找自己构建数据库中的内容返回给你想要的东西。哪哪都是爬虫！
#### 2、URI和URL是什么
在访问网上的资源的时候，普通可能会问地址是什么，而程序猿一般会问URL是什么。但其实除了URL，还有URI。那么URL、URI究竟是啥呢？和地址有啥不同呢？(其实还有URN)
先给一张图
![图1](https://github.com/lewiscrow/spider-python/blob/master/images/day1-1.png)
URI(Uniform Resource Identifier，URI)可被视为定位符（Uniform Resource Locator,URL），名称（Uniform Resource Name,URN）或两者兼备。统一资源名（URN）如同一个人的名称，而统一资源定位符（URL）代表一个人的住址。换言之，URN定义某事物的身份，而URL提供查找该事物的方法。
用于标识唯一书目的ISBN系统是一个典型的URN使用范例。例如，ISBN 0-486-27557-4无二义性地标识出莎士比亚的戏剧《罗密欧与朱丽叶》的某一特定版本。为获得该资源并阅读该书，人们需要它的位置，也就是一个URL地址。在类Unix操作系统中，一个典型的URL地址可能是一个文件目录，例如file:///home/username/RomeoAndJuliet.pdf。该URL标识出存储于本地硬盘中的电子书文件。因此，URL和URN有着互补的作用。
URN就如同上面图书的索引一样，命名规则可以人为进行定制。其实如果这世界上的人的名字不能重复，那么名字也可以作为人的URN。
而URL的意义就比较规范了，URL通常由三部分组成：
* 访问资源的命名机制
* 存放资源的主机名
* 资源自身的名称
比如说我这个项目在github上的仓库中readme的URL，`https://github.com/lewiscrow/spider-python/blob/master/README.md`。首先，这个资源通过https访问；其次，这个资源存放的主机为github的服务器；最后，这个资源自身的名称表示了这个资源在该服务器上的位置。由这三者，可以唯一确定一个资源在互联网中的位置，从而我们可以准确无误的拿到它。
#### 3、爬虫的原理
我们爬虫的目的，就是为了爬取网站上的内容和资源。当知道了资源的URL（为啥不用URN呢？因为知道了也没啥用）之后，我们就可以把这些内容爬取到自己的电脑上。一些比较简单的资源，比如说直接渲染在html里面的内容，我们就可以直接获取网页的html进行解析，麻烦点可能需要针对标签、标签的id、特定css样式的内容进行筛选。比较麻烦的内容，比如说二次请求动态窗口显示、图片代替文字显示、隐含规则的请求地址，这些就需要我们针对性的进行操作。更麻烦的，有验证码的、登录的、cookie验证、操作频率检查的、请求检查是否由浏览器发出的等等，则需要我们充分发挥程序员的聪明才智，进行破解。真正的爬虫大师，只要网上有的，都能给你爬下来！
#### 4、环境要求
B吹完了，开始整点实际的。本次使用python版本3.7，软件有Anaconda以及pycharm，前者用于使用notebook进行分步测试，后者用于构建py文件整点运行，好好搭配，干活不累。
好了，明天我们讲一下如何使用一些基本的库获取到一些网站的资源，并把他们显示出来，或者保存到本地。
